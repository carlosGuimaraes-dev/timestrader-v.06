{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "XWqhE-eMcrSn",
      "metadata": {
        "id": "XWqhE-eMcrSn"
      },
      "source": [
        "# 1) Setup & Install\n",
        "Install dependencies for Gymnasium and Stable-Baselines3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91149d46",
      "metadata": {
        "id": "91149d46"
      },
      "outputs": [],
      "source": [
        "# 1) Setup & Install — deps for RL and plotting\n",
        "# First, uninstall conflicting packages that may be pre-installed in the Colab environment.\n",
        "!pip uninstall -y dopamine-rl gym > /dev/null 2>&1\n",
        "\n",
        "# Install stable, non-yanked versions of SB3 and Gymnasium known to be compatible.\n",
        "!pip -q install gymnasium==0.28.1 stable-baselines3==2.2.1 tensorboard matplotlib pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9QptH4HRcrSp",
      "metadata": {
        "id": "9QptH4HRcrSp"
      },
      "source": [
        "# 2) Google Drive Mount\n",
        "Access TimesNet embeddings stored in Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Etn6wwtWcrSq",
      "metadata": {
        "id": "Etn6wwtWcrSq"
      },
      "outputs": [],
      "source": [
        "# 2) Google Drive Mount — access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y8FFJ5m-crSq",
      "metadata": {
        "id": "y8FFJ5m-crSq"
      },
      "source": [
        "# 3) Configuration\n",
        "Paths, market specifics, costs, rewards, Guardian thresholds, and PPO hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53e0313",
      "metadata": {
        "id": "a53e0313"
      },
      "outputs": [],
      "source": [
        "# 3) Configuration — paths and parameters\n",
        "import os\n",
        "\n",
        "# Data paths (TimesNet embeddings)\n",
        "DATA_DIR = '/content/drive/MyDrive/timesnet_mnq/embeddings/'  # Corrected to be a directory\n",
        "TRAIN_NPZ = os.path.join(DATA_DIR, 'train_emb_avg.npz')\n",
        "VAL_NPZ   = os.path.join(DATA_DIR, 'val_emb_avg.npz')\n",
        "TEST_NPZ  = os.path.join(DATA_DIR, 'test_emb_avg.npz')\n",
        "META_JSON = os.path.join(DATA_DIR, 'embeddings_meta.json')\n",
        "\n",
        "# OHLC paths for ATR only (no direct use in observations)\n",
        "RAW_DATA_DIR = '/content'  # where you upload mnq_complete_dataset.csv in Colab\n",
        "TRAIN_OHLC_CSV = os.path.join(RAW_DATA_DIR, 'mnq_train.csv')\n",
        "VAL_OHLC_CSV   = os.path.join(RAW_DATA_DIR, 'mnq_val.csv')\n",
        "TEST_OHLC_CSV  = os.path.join(RAW_DATA_DIR, 'mnq_test.csv')\n",
        "OHLC_RESAMPLE_RULE = '5min'  # aggregate 1-min to 5-min to match TimesNet (pandas>=2 warning safe)\n",
        "\n",
        "# Bar timing (5-minute bars) and annualization\n",
        "BAR_SECONDS = 300\n",
        "STEPS_PER_DAY = 288  # 24*60/5\n",
        "STEPS_PER_YEAR = int(STEPS_PER_DAY * 252)\n",
        "\n",
        "# Market specifics\n",
        "POINT_VALUE_MNQ = 2.0      # USD per point\n",
        "TICK_SIZE = 0.25\n",
        "TICK_VALUE_USD = POINT_VALUE_MNQ * TICK_SIZE  # $0.50 per tick\n",
        "\n",
        "# Costs and toggles\n",
        "FIXED_COMMISSION_USD = 0.10  # round-trip all-in (entry+exit)\n",
        "# Slippage fixo em ticks (round-trip modelado na entrada); baseline off\n",
        "FIXED_SLIPPAGE_TICKS = 0\n",
        "FIXED_SLIPPAGE_USD = FIXED_SLIPPAGE_TICKS * TICK_VALUE_USD\n",
        "ATR_SLIPPAGE_MULTIPLIER = 0.25  # deprecated\n",
        "# Experiment toggles (mude 1 por vez)\n",
        "TRAIN_SLIPPAGE_ON = False\n",
        "EVAL_SLIPPAGE_ON = False\n",
        "GUARDIAN_TIGHT = False  # se True, usa SL/TS 1.5x e BE 1.0x\n",
        "\n",
        "# Risk parameters (training env termination)\n",
        "MAX_EPISODE_DRAWDOWN_USD = 500.0\n",
        "\n",
        "# Reward policy coefficients (scaled to be impactful)\n",
        "# For a $20 drawdown: penalty = 0.0002 * (20**2) = 0.08\n",
        "# Profit bonus disabled initially to simplify learning\n",
        "DRAWDOWN_PENALTY_COEFF = 0.0\n",
        "PROFIT_KEEPING_BONUS_COEFF = 0.0\n",
        "PATIENCE_BONUS = 0.0\n",
        "CHOPPY_ATR_TO_PRICE_MAX = 0.0\n",
        "\n",
        "# Guardian thresholds (backtest only, ATR-based)\n",
        "GUARDIAN_SL_ATR_MULTIPLIER = 2.0\n",
        "GUARDIAN_TS_ATR_MULTIPLIER = 2.0\n",
        "GUARDIAN_BE_ACTIVATION_ATR_MULTIPLIER = 1.5\n",
        "GUARDIAN_BE_PLUS_TICKS = 2  # +2 ticks beyond entry when BE activates\n",
        "\n",
        "# Environment\n",
        "EPISODE_LENGTH = 1024\n",
        "N_ENVS = 8\n",
        "SEED = 42\n",
        "\n",
        "# PPO (SB3) hyperparameters — tuned for L4 22GB (cap 75% VRAM)\n",
        "# Keep rollout size constant, increase batch to leverage GPU without exceeding memory cap.\n",
        "PPO_KW = dict(\n",
        "    learning_rate=3e-4,\n",
        "    n_steps=2048,             # with N_ENVS=8 → rollout = 16384\n",
        "    batch_size=1024,          # divisor of rollout; increases GPU utilization\n",
        "    n_epochs=6,               # fewer epochs with larger batch\n",
        "    gamma=0.99,\n",
        "    gae_lambda=0.95,\n",
        "    clip_range=0.2,\n",
        "    ent_coef=0.005,           # fixed (schedule disabled for stability)\n",
        "    vf_coef=0.5,\n",
        "    max_grad_norm=0.5,\n",
        "    target_kl=0.03,           # early stop PPO updates if divergence too high\n",
        ")\n",
        "\n",
        "# Training run cadence\n",
        "TOTAL_TIMESTEPS = 1_000_000\n",
        "EVAL_FREQ_STEPS = 20480\n",
        "LOG_DIR = '/content/drive/MyDrive/timesnet_mnq/ppo_logs'\n",
        "BEST_MODEL_PATH = os.path.join(LOG_DIR, 'best_model.zip')\n",
        "os.makedirs(LOG_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aa538d",
      "metadata": {
        "id": "54aa538d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Assuming DATA_DIR is correctly set in a previous cell\n",
        "# If not, you may need to define it here or run the configuration cell first.\n",
        "try:\n",
        "    with np.load(TRAIN_NPZ, allow_pickle=False) as Z:\n",
        "        print(f\"Keys in {TRAIN_NPZ}: {list(Z.keys())}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {TRAIN_NPZ} not found. Please ensure DATA_DIR is set correctly and the file exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2191fec",
      "metadata": {
        "id": "a2191fec"
      },
      "source": [
        "# 4) Imports & Utilities\n",
        "Helpers for data loading and metrics (Calmar, Sharpe, MDD).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f904ed4d",
      "metadata": {
        "id": "f904ed4d"
      },
      "outputs": [],
      "source": [
        "# 4) Imports & Utilities — loaders and metrics\n",
        "import json, math\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional\n",
        "\n",
        "def _read_ohlc_csv(csv_path: str, resample_rule: Optional[str] = None):\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.columns = [c.strip().lower() for c in df.columns]\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "        df = df.sort_values('timestamp').set_index('timestamp')\n",
        "    if resample_rule:\n",
        "        # Match TimesNet resample semantics: right-closed, right-labeled bars\n",
        "        agg_base = {'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum'}\n",
        "        agg = {col: agg_base.get(col, 'last') for col in df.columns}\n",
        "        df = df.resample(resample_rule, label='right', closed='right').agg(agg)\n",
        "        df = df.dropna(how='any').reset_index()\n",
        "    return df\n",
        "\n",
        "def _atr_wilder(high: np.ndarray, low: np.ndarray, close: np.ndarray, period: int = 14) -> np.ndarray:\n",
        "    high = high.astype(np.float64)\n",
        "    low = low.astype(np.float64)\n",
        "    close = close.astype(np.float64)\n",
        "    n = len(close)\n",
        "    atr = np.empty(n, dtype=np.float64)\n",
        "    prev_close = close[0]\n",
        "    tr0 = max(high[0]-low[0], abs(high[0]-prev_close), abs(low[0]-prev_close))\n",
        "    atr[0] = tr0\n",
        "    for t in range(1, n):\n",
        "        tr = max(high[t]-low[t], abs(high[t]-close[t-1]), abs(low[t]-close[t-1]))\n",
        "        if t < period:\n",
        "            atr[t] = (atr[t-1]*t + tr) / (t+1)\n",
        "        else:\n",
        "            atr[t] = (atr[t-1]*(period-1) + tr) / period\n",
        "    return atr\n",
        "\n",
        "def load_split(npz_path: str, ohlc_csv_path: Optional[str] = None, resample_rule: Optional[str] = None, atr_period: int = 14):\n",
        "    with np.load(npz_path, allow_pickle=False) as Z:\n",
        "        obs = Z['obs'] if 'obs' in Z.files else Z['X']\n",
        "        start_idx = Z['start_idx']\n",
        "        end_idx = Z['end_idx']\n",
        "        close = Z['close'] if 'close' in Z.files else None\n",
        "        atr = None\n",
        "        for k in ['atr', 'ATR', 'atr_14', 'ATR_14']:\n",
        "            if k in Z.files:\n",
        "                atr = Z[k]\n",
        "                break\n",
        "    if close is None:\n",
        "        raise ValueError('NPZ must contain close series')\n",
        "    if ohlc_csv_path:\n",
        "        df = _read_ohlc_csv(ohlc_csv_path, resample_rule)\n",
        "        for col in ['high','low','close']:\n",
        "            if col not in df.columns:\n",
        "                raise ValueError(f'OHLC CSV must contain {col} column')\n",
        "        atr_ohlc = _atr_wilder(df['high'].to_numpy(), df['low'].to_numpy(), df['close'].to_numpy(), period=atr_period)\n",
        "        if len(atr_ohlc) != len(close):\n",
        "            raise ValueError(f'Length mismatch between OHLC ({len(atr_ohlc)}) and NPZ close ({len(close)}). Provide split-matching OHLC CSV or adjust resample_rule.')\n",
        "        atr = atr_ohlc\n",
        "    if atr is None:\n",
        "        raise ValueError(\"ATR not found. Provide ohlc_csv_path for ATR computation or include an 'atr' series in the NPZ.\")\n",
        "    return obs.astype(np.float32), start_idx.astype(np.int64), end_idx.astype(np.int64), close.astype(np.float64), atr.astype(np.float64)\n",
        "\n",
        "def synth_time_features(n: int, steps_per_day: int = STEPS_PER_DAY) -> np.ndarray:\n",
        "    t = np.arange(n, dtype=np.float32)\n",
        "    hour_phase = 2*np.pi * (t % steps_per_day) / max(steps_per_day, 1)\n",
        "    week_phase = 2*np.pi * (t % (steps_per_day*5)) / max(steps_per_day*5, 1)\n",
        "    return np.stack([np.sin(hour_phase), np.cos(hour_phase), np.sin(week_phase), np.cos(week_phase)], axis=1).astype(np.float32)\n",
        "\n",
        "def map_action_to_position(action: int) -> int:\n",
        "    # 0->short(-1), 1->flat(0), 2->long(+1)\n",
        "    return (-1 if action == 0 else (0 if action == 1 else 1))\n",
        "\n",
        "def pnl_from_price_change(prev_pos: int, price_change: float, point_value: float) -> float:\n",
        "    return float(prev_pos * price_change * point_value)\n",
        "\n",
        "def compute_drawdown(equity: np.ndarray) -> np.ndarray:\n",
        "    # Robust to negative equity: clamp ratio to [0,1] so DD ∈ [0,100%]\n",
        "    peaks = np.maximum.accumulate(np.maximum(equity, 1e-9))\n",
        "    ratio = np.divide(equity, peaks, out=np.zeros_like(peaks, dtype=np.float64), where=peaks>0)\n",
        "    dd = 1.0 - np.clip(ratio, 0.0, 1.0)\n",
        "    return dd\n",
        "\n",
        "def max_drawdown(equity: np.ndarray) -> float:\n",
        "    dd = compute_drawdown(equity)\n",
        "    return float(np.nanmax(dd) if len(dd) else 0.0)\n",
        "\n",
        "def cagr_from_equity(equity: np.ndarray) -> float:\n",
        "    n = len(equity)\n",
        "    if n < 2:\n",
        "        return 0.0\n",
        "    start = float(equity[0])\n",
        "    years = n / max(STEPS_PER_YEAR, 1)\n",
        "    if years <= 0 or start <= 0:\n",
        "        return 0.0\n",
        "    end = float(equity[-1])\n",
        "    if end <= 0:\n",
        "        return -1.0\n",
        "    ratio = end / start\n",
        "    return float(ratio ** (1.0 / years) - 1.0)\n",
        "\n",
        "def calmar_ratio(equity: np.ndarray) -> float:\n",
        "    mdd = max_drawdown(equity)\n",
        "    cagr = cagr_from_equity(equity)\n",
        "    if not np.isfinite(mdd) or not np.isfinite(cagr):\n",
        "        return 0.0\n",
        "    if mdd <= 1e-12:\n",
        "        return float('inf') if cagr > 0 else 0.0\n",
        "    return cagr / mdd\n",
        "\n",
        "def sharpe_ratio(returns: np.ndarray, risk_free=0.0) -> float:\n",
        "    if len(returns) < 2:\n",
        "        return 0.0\n",
        "    mean = float(np.mean(returns))\n",
        "    std = float(np.std(returns, ddof=1))\n",
        "    if std <= 1e-12:\n",
        "        return 0.0\n",
        "    ann_factor = math.sqrt(STEPS_PER_YEAR)\n",
        "    return float((mean - risk_free) / std * ann_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "materialize_ohlc"
      },
      "outputs": [],
      "source": [
        "# 3b) Materializar OHLC por split para ATR (alinha com os NPZ)\n",
        "# Use quando você tiver um único CSV base (mnq_complete_dataset.csv) e quiser gerar train/val/test CSVs.\n",
        "# Requer que os NPZ (TRAIN_NPZ/VAL_NPZ/TEST_NPZ) já existam no DATA_DIR.\n",
        "import numpy as np, pandas as pd\n",
        "BASE_OHLC_CSV = os.path.join(RAW_DATA_DIR, 'mnq_complete_dataset.csv')\n",
        "if os.path.exists(BASE_OHLC_CSV):\n",
        "    df_all = _read_ohlc_csv(BASE_OHLC_CSV, resample_rule=OHLC_RESAMPLE_RULE)\n",
        "    def _len_close(npz_path):\n",
        "        with np.load(npz_path, allow_pickle=False) as Z:\n",
        "            return len(Z['close'] if 'close' in Z.files else Z['X'])\n",
        "    n_train = _len_close(TRAIN_NPZ)\n",
        "    n_val   = _len_close(VAL_NPZ)\n",
        "    n_test  = _len_close(TEST_NPZ)\n",
        "    total   = n_train + n_val + n_test\n",
        "    if len(df_all) < total:\n",
        "        raise ValueError(f'OHLC length {len(df_all)} < NPZ total {total}. Verifique CSV base e resample.')\n",
        "    # Compensa warm-up/limpezas no TimesNet: corta excesso do início para casar os comprimentos\n",
        "    excess = len(df_all) - total\n",
        "    if excess > 0:\n",
        "        df_all = df_all.iloc[excess:]\n",
        "    assert len(df_all) == total\n",
        "    os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
        "    _train_csv = os.path.join(RAW_DATA_DIR, 'mnq_train.csv')\n",
        "    _val_csv   = os.path.join(RAW_DATA_DIR, 'mnq_val.csv')\n",
        "    _test_csv  = os.path.join(RAW_DATA_DIR, 'mnq_test.csv')\n",
        "    df_all.iloc[:n_train].to_csv(_train_csv, index=False)\n",
        "    df_all.iloc[n_train:n_train+n_val].to_csv(_val_csv, index=False)\n",
        "    df_all.iloc[n_train+n_val:].to_csv(_test_csv, index=False)\n",
        "    print('Wrote:', _train_csv, _val_csv, _test_csv)\n",
        "    # Atualiza caminhos usados pelo PPO\n",
        "    TRAIN_OHLC_CSV = _train_csv\n",
        "    VAL_OHLC_CSV   = _val_csv\n",
        "    TEST_OHLC_CSV  = _test_csv\n",
        "else:\n",
        "    print('BASE_OHLC_CSV não encontrado; pule esta célula se já tiver os CSVs por split.')\n"
      ],
      "id": "materialize_ohlc"
    },
    {
      "cell_type": "markdown",
      "id": "gpu_tuning_hdr",
      "metadata": {
        "id": "gpu_tuning_hdr"
      },
      "source": [
        "# 3c) GPU Tuning (L4 22GB)\n",
        "Limit VRAM to 75% and enable fast matmul (TF32) when available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gpu_tuning_cell",
      "metadata": {
        "id": "gpu_tuning_cell"
      },
      "outputs": [],
      "source": [
        "# 3c) GPU Tuning — cap VRAM and enable fast matmul\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            torch.cuda.set_per_process_memory_fraction(0.75)\n",
        "        except Exception as e:\n",
        "            print('Warn: set_per_process_memory_fraction not supported:', e)\n",
        "        try:\n",
        "            torch.set_float32_matmul_precision('high')  # TF32 on Ampere+\n",
        "        except Exception:\n",
        "            pass\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "        free, t = torch.cuda.mem_get_info()\n",
        "        print(f'GPU: total={total:.1f} GB | free={(free/1024**3):.1f} GB (cap 75%)')\n",
        "except Exception as e:\n",
        "    print('GPU tuning cell skipped:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bsCOCr0ocrSs",
      "metadata": {
        "id": "bsCOCr0ocrSs"
      },
      "source": [
        "# 5) Environment (MNQEmbEnv)\n",
        "Training-only risk shaping on embeddings; no hard stops.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00036e3d",
      "metadata": {
        "id": "00036e3d"
      },
      "outputs": [],
      "source": [
        "# 5) Environment — MNQEmbEnv\n",
        "class MNQEmbEnv(gym.Env):\n",
        "    metadata = {'render.modes': []}\n",
        "    def __init__(\n",
        "        self,\n",
        "        npz_path: str,\n",
        "        meta_path: Optional[str] = None,\n",
        "        ohlc_csv_path: Optional[str] = None,\n",
        "        ohlc_resample_rule: Optional[str] = None,\n",
        "        episode_length: int = EPISODE_LENGTH,\n",
        "        point_value: float = POINT_VALUE_MNQ,\n",
        "        fixed_commission_usd: float = FIXED_COMMISSION_USD,\n",
        "        fixed_slippage_usd: float = FIXED_SLIPPAGE_USD,\n",
        "        drawdown_penalty_coeff: float = DRAWDOWN_PENALTY_COEFF,\n",
        "        profit_keeping_bonus_coeff: float = PROFIT_KEEPING_BONUS_COEFF,\n",
        "        patience_bonus: float = PATIENCE_BONUS,\n",
        "        choppy_atr_to_price_max: float = CHOPPY_ATR_TO_PRICE_MAX,\n",
        "        max_episode_drawdown_usd: float = MAX_EPISODE_DRAWDOWN_USD,\n",
        "        apply_slippage_costs: bool = False,\n",
        "        seed: Optional[int] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.obs_raw, self.start_idx, self.end_idx, self.close, self.atr = load_split(npz_path, ohlc_csv_path=ohlc_csv_path, resample_rule=ohlc_resample_rule)\n",
        "        self.meta = {}\n",
        "        if meta_path and os.path.exists(meta_path):\n",
        "            with open(meta_path, 'r') as f:\n",
        "                self.meta = json.load(f)\n",
        "        self.T, self.D = self.obs_raw.shape\n",
        "        self.time_features = synth_time_features(self.T, STEPS_PER_DAY)\n",
        "        self.point_value = float(point_value)\n",
        "        self.fixed_commission = float(fixed_commission_usd)\n",
        "        self.fixed_slippage = float(fixed_slippage_usd)\n",
        "        self.apply_slippage_costs = bool(apply_slippage_costs)\n",
        "        self.dd_penalty = float(drawdown_penalty_coeff)\n",
        "        self.profit_bonus = float(profit_keeping_bonus_coeff)\n",
        "        self.patience_bonus_v = float(patience_bonus)\n",
        "        self.choppy_thr = float(choppy_atr_to_price_max)\n",
        "        self.max_episode_dd = float(max_episode_drawdown_usd)\n",
        "        self.episode_length = int(episode_length)\n",
        "\n",
        "        # Observation: [embedding D] + [time 4] + [position 1] + [portfolio 3]\n",
        "        self.obs_dim = self.D + 4 + 1 + 3\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_dim,), dtype=np.float32)\n",
        "        self._reset_state()\n",
        "\n",
        "    def _reset_state(self):\n",
        "        min_start = 1\n",
        "        max_start = max(min_start, self.T - self.episode_length - 2)\n",
        "        self.start = int(self.rng.integers(min_start, max_start+1)) if max_start > min_start else min_start\n",
        "        self.step_in_ep = 0\n",
        "        self.current_step = self.start\n",
        "        self.current_position = 0\n",
        "        self.entry_price = 0.0\n",
        "        self.best_price = 0.0\n",
        "        self.entry_step = 0\n",
        "        self.equity = 1000.0\n",
        "        self.peak_equity = self.equity\n",
        "        self.equity_series = [self.equity]\n",
        "        self.returns_series = []\n",
        "\n",
        "    def is_market_choppy(self, t: int) -> bool:\n",
        "        price = float(self.close[t])\n",
        "        if price <= 0:\n",
        "            return False\n",
        "        return (float(self.atr[t]) / price) <= self.choppy_thr\n",
        "\n",
        "    def _get_obs(self) -> np.ndarray:\n",
        "        emb = self.obs_raw[self.current_step].astype(np.float32)\n",
        "        tf = self.time_features[self.current_step].astype(np.float32)\n",
        "        pf = np.array([self.current_position], dtype=np.float32)\n",
        "        # === Portfolio features ===\n",
        "        if self.current_position != 0:\n",
        "            atr_entry = float(max(self.atr[self.entry_step], 1e-9))\n",
        "            pnl_usd = (float(self.close[self.current_step]) - self.entry_price) * self.current_position * self.point_value\n",
        "            pnl_norm = float(pnl_usd) / max(atr_entry * self.point_value, 1e-9)\n",
        "            bars_in_trade = max(0, self.current_step - int(self.entry_step))\n",
        "        else:\n",
        "            pnl_norm = 0.0\n",
        "            bars_in_trade = 0\n",
        "        dur_norm = float(bars_in_trade) / max(self.episode_length, 1)\n",
        "        dd_usd = float(self.peak_equity - self.equity)\n",
        "        dd_norm = dd_usd / max(self.max_episode_dd, 1e-6)\n",
        "        portfolio_state = np.array([pnl_norm, dur_norm, dd_norm], dtype=np.float32)\n",
        "        return np.concatenate([emb, tf, pf, portfolio_state], axis=0)\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, options=None):\n",
        "        if seed is not None:\n",
        "            self.rng = np.random.default_rng(seed)\n",
        "        self._reset_state()\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def step(self, action: int):\n",
        "        new_pos = map_action_to_position(int(action))\n",
        "        prev_pos = self.current_position\n",
        "        t = self.current_step\n",
        "        prev_t = max(0, t-1)\n",
        "\n",
        "        # Price change and gross PnL for the previous position\n",
        "        price_change = float(self.close[t] - self.close[prev_t])\n",
        "        gross_pnl = pnl_from_price_change(prev_pos, price_change, self.point_value)\n",
        "\n",
        "        # Transaction costs: charge full round-trip cost only on new trade entry (from flat or reversal)\n",
        "        costs = 0.0\n",
        "        is_new_trade_entry = ((prev_pos == 0 and new_pos != 0) or\n",
        "                              (np.sign(new_pos) != np.sign(prev_pos) and new_pos != 0))\n",
        "        # Report slippage, but do not apply to equity unless enabled\n",
        "        entry_intended_price = None\n",
        "        entry_fill_price_reported = None\n",
        "        entry_slippage_ticks = 0\n",
        "        entry_slippage_usd = 0.0\n",
        "        if is_new_trade_entry:\n",
        "            commission = self.fixed_commission\n",
        "            # Reported slippage: assume adverse 2 ticks from intended price\n",
        "            entry_intended_price = float(self.close[t])\n",
        "            entry_slippage_ticks = int(FIXED_SLIPPAGE_TICKS)\n",
        "            entry_slippage_usd = float(self.fixed_slippage)\n",
        "            entry_fill_price_reported = entry_intended_price + (entry_slippage_ticks * TICK_SIZE)\n",
        "            slippage_cost = (self.fixed_slippage if self.apply_slippage_costs else 0.0)\n",
        "            costs = commission + slippage_cost\n",
        "        base_reward = gross_pnl - costs\n",
        "\n",
        "        # Unrealized PnL of the active trade (based on prev_pos and prior entry)\n",
        "        if prev_pos != 0:\n",
        "            unrealized_pnl_prev = (float(self.close[t]) - self.entry_price) * prev_pos * self.point_value\n",
        "        else:\n",
        "            unrealized_pnl_prev = 0.0\n",
        "\n",
        "        # Risk penalties and behavioral incentives\n",
        "        current_trade_drawdown = max(0.0, -unrealized_pnl_prev)\n",
        "        drawdown_penalty = self.dd_penalty * (current_trade_drawdown ** 2)\n",
        "        current_trade_profit = max(0.0, unrealized_pnl_prev)\n",
        "        profit_keeping_bonus = self.profit_bonus * current_trade_profit\n",
        "        patience_bonus = (self.patience_bonus_v if self.is_market_choppy(t) and new_pos == 0 else\n",
        "                          (-self.patience_bonus_v if self.is_market_choppy(t) and new_pos != 0 else 0.0))\n",
        "        final_reward = base_reward - drawdown_penalty + profit_keeping_bonus + patience_bonus\n",
        "\n",
        "        # Update equity statistics\n",
        "        self.equity += gross_pnl - costs\n",
        "        self.returns_series.append((gross_pnl - costs) / max(abs(self.equity_series[-1]), 1e-9))\n",
        "        self.equity_series.append(self.equity)\n",
        "        self.peak_equity = max(self.peak_equity, self.equity)\n",
        "        episode_drawdown = self.peak_equity - self.equity\n",
        "        terminated = episode_drawdown > self.max_episode_dd\n",
        "\n",
        "        # Trade state management: handle new entries, exits, and reversals\n",
        "        position_flipped = (np.sign(new_pos) != np.sign(prev_pos))\n",
        "        if (prev_pos == 0 and new_pos != 0) or (position_flipped and new_pos != 0):\n",
        "            # New trade started (from flat or by reversal)\n",
        "            self.entry_price = float(self.close[t])\n",
        "            self.best_price = self.entry_price\n",
        "            self.entry_step = int(t)\n",
        "        elif new_pos == 0 and prev_pos != 0:\n",
        "            # Trade closed\n",
        "            self.entry_price = 0.0\n",
        "            self.best_price = 0.0\n",
        "            self.entry_step = int(self.current_step)\n",
        "        elif new_pos == prev_pos and new_pos != 0:\n",
        "            # Position maintained: update best price favorably\n",
        "            if new_pos > 0:\n",
        "                self.best_price = max(self.best_price, float(self.close[t]))\n",
        "            else:\n",
        "                self.best_price = min(self.best_price, float(self.close[t]))\n",
        "\n",
        "        # Advance step\n",
        "        self.current_position = new_pos\n",
        "        self.current_step += 1\n",
        "        self.step_in_ep += 1\n",
        "        truncated = (self.step_in_ep >= self.episode_length) or (self.current_step >= (self.T - 1))\n",
        "        obs = self._get_obs()\n",
        "        info = {\n",
        "            'gross_pnl': gross_pnl,\n",
        "            'costs': costs,\n",
        "            'equity': self.equity,\n",
        "            'drawdown': episode_drawdown,\n",
        "            'position': self.current_position,\n",
        "            'entry_intended_price': entry_intended_price,\n",
        "            'entry_fill_price_reported': entry_fill_price_reported,\n",
        "            'entry_slippage_ticks': entry_slippage_ticks,\n",
        "            'entry_slippage_usd': entry_slippage_usd,\n",
        "        }\n",
        "        return obs, float(final_reward), bool(terminated), bool(truncated), info\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfc606ad",
      "metadata": {
        "id": "cfc606ad"
      },
      "source": [
        "# 6) Guardian & Backtester\n",
        "Guardian applies SL/TS/BE in inference; backtester runs full pass.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1199aa85",
      "metadata": {
        "id": "1199aa85"
      },
      "outputs": [],
      "source": [
        "# 6) Guardian & Backtester — inference safety layer\n",
        "class Guardian:\n",
        "    def __init__(self, point_value=POINT_VALUE_MNQ,\n",
        "                 sl_atr_mult=GUARDIAN_SL_ATR_MULTIPLIER,\n",
        "                 ts_atr_mult=GUARDIAN_TS_ATR_MULTIPLIER,\n",
        "                 be_activation_atr_mult=GUARDIAN_BE_ACTIVATION_ATR_MULTIPLIER,\n",
        "                 be_plus_ticks=GUARDIAN_BE_PLUS_TICKS):\n",
        "        self.point_value = float(point_value)\n",
        "        self.sl_mult = float(sl_atr_mult)\n",
        "        self.ts_mult = float(ts_atr_mult)\n",
        "        self.be_act_mult = float(be_activation_atr_mult)\n",
        "        self.be_plus_ticks = int(be_plus_ticks)\n",
        "\n",
        "def run_backtest(model, env_like: MNQEmbEnv, guardian: Guardian, deterministic=True, collect_reports=False):\n",
        "    obs_raw = env_like.obs_raw\n",
        "    close = env_like.close\n",
        "    atr = env_like.atr\n",
        "    T = min(len(obs_raw), len(close), len(atr))\n",
        "    close = close[:T]\n",
        "    atr = atr[:T]\n",
        "    position = 0\n",
        "    entry_price = 0.0\n",
        "    entry_step = None\n",
        "    best_price = 0.0\n",
        "    be_activated = False\n",
        "    stop_level = None\n",
        "    equity = 1000.0\n",
        "    peak_equity = equity\n",
        "    equity_series = [equity]\n",
        "    step_returns = []\n",
        "    tf_all = synth_time_features(T, STEPS_PER_DAY)\n",
        "    trade_reports = [] if collect_reports else None\n",
        "    for t in range(1, T):\n",
        "        # 1) Guardian updates and veto (if position open)\n",
        "        if position != 0:\n",
        "            # Initial hard stop if just opened\n",
        "            if stop_level is None:\n",
        "                if position > 0:\n",
        "                    stop_level = entry_price - guardian.sl_mult * float(atr[t])\n",
        "                else:\n",
        "                    stop_level = entry_price + guardian.sl_mult * float(atr[t])\n",
        "            # Break-even activation\n",
        "            be_trigger = guardian.be_act_mult * float(atr[t])\n",
        "            be_offset = guardian.be_plus_ticks * TICK_SIZE\n",
        "            if not be_activated:\n",
        "                if position > 0 and (float(close[t]) - entry_price) >= be_trigger:\n",
        "                    stop_level = max(stop_level, entry_price + be_offset)\n",
        "                    be_activated = True\n",
        "                elif position < 0 and (entry_price - float(close[t])) >= be_trigger:\n",
        "                    stop_level = min(stop_level, entry_price - be_offset)\n",
        "                    be_activated = True\n",
        "            # Trailing stop\n",
        "            if position > 0:\n",
        "                trail = best_price - guardian.ts_mult * float(atr[t])\n",
        "                stop_level = max(stop_level, trail)\n",
        "            else:\n",
        "                trail = best_price + guardian.ts_mult * float(atr[t])\n",
        "                stop_level = min(stop_level, trail)\n",
        "            # Veto: close if price crosses stop\n",
        "            if (position > 0 and float(close[t]) <= stop_level) or (position < 0 and float(close[t]) >= stop_level):\n",
        "                # Apply PnL for this step (no extra costs; paid on entry)\n",
        "                price_change = float(close[t] - close[t-1])\n",
        "                gross_pnl = pnl_from_price_change(position, price_change, env_like.point_value)\n",
        "                equity += gross_pnl\n",
        "                peak_equity = max(peak_equity, equity)\n",
        "                equity_series.append(equity)\n",
        "                step_returns.append(gross_pnl / max(abs(equity_series[-2]), 1e-9))\n",
        "                # Close position and reset trade state\n",
        "                position = 0\n",
        "                entry_price = 0.0\n",
        "                entry_step = None\n",
        "                best_price = 0.0\n",
        "                be_activated = False\n",
        "                stop_level = None\n",
        "                continue\n",
        "\n",
        "        # 2) PPO acts if Guardian did not veto\n",
        "\n",
        "        # === CONSTRUÇÃO DE ESTADO IDÊNTICA AO AMBIENTE DE TREINO ===\n",
        "        if position != 0:\n",
        "            atr_entry_idx = entry_step if entry_step is not None else t\n",
        "            atr_entry = float(max(atr[atr_entry_idx], 1e-9))\n",
        "            pnl_usd = (float(close[t]) - entry_price) * position * env_like.point_value\n",
        "            pnl_norm = pnl_usd / max(atr_entry * env_like.point_value, 1e-9)\n",
        "            bars_in_trade = max(0, t - atr_entry_idx)\n",
        "        else:\n",
        "            pnl_norm = 0.0\n",
        "            bars_in_trade = 0\n",
        "\n",
        "        dur_norm = float(bars_in_trade) / max(EPISODE_LENGTH, 1)\n",
        "        dd_usd = float(max(peak_equity - equity, 0.0))\n",
        "        dd_norm = dd_usd / max(MAX_EPISODE_DRAWDOWN_USD, 1e-6)\n",
        "\n",
        "        portfolio_state = np.array([pnl_norm, dur_norm, dd_norm], dtype=np.float32)\n",
        "        state = np.concatenate([\n",
        "            obs_raw[t].astype(np.float32),\n",
        "            tf_all[t].astype(np.float32),\n",
        "            np.array([position], dtype=np.float32),\n",
        "            portfolio_state\n",
        "        ])\n",
        "        # ==========================================================\n",
        "\n",
        "        action, _ = model.predict(state, deterministic=deterministic)\n",
        "        desired_pos = map_action_to_position(int(action))\n",
        "\n",
        "        # 3) Execute decision (apply PnL for previous position)\n",
        "        prev_pos = position\n",
        "        price_change = float(close[t] - close[t-1])\n",
        "        gross_pnl = pnl_from_price_change(prev_pos, price_change, env_like.point_value)\n",
        "        costs = 0.0\n",
        "        is_new_trade_entry = ((prev_pos == 0 and desired_pos != 0) or (np.sign(desired_pos) != np.sign(prev_pos) and desired_pos != 0))\n",
        "        # Report slippage, but do not apply to equity unless enabled\n",
        "        if is_new_trade_entry:\n",
        "            commission = env_like.fixed_commission\n",
        "            slippage_cost = (env_like.fixed_slippage if getattr(env_like, 'apply_slippage_costs', False) else 0.0)\n",
        "            costs = commission + slippage_cost\n",
        "            # Build trade report (entry)\n",
        "            if collect_reports:\n",
        "                intended_price = float(close[t])\n",
        "                slip_ticks = int(FIXED_SLIPPAGE_TICKS)\n",
        "                fill_price_reported = intended_price + (slip_ticks * TICK_SIZE)\n",
        "                trade_reports.append(dict(\n",
        "                    t=int(t),\n",
        "                    side=int(np.sign(desired_pos)),\n",
        "                    entry_intended_price=intended_price,\n",
        "                    entry_fill_price_reported=fill_price_reported,\n",
        "                    entry_slippage_ticks=slip_ticks,\n",
        "                    entry_slippage_usd=float(env_like.fixed_slippage),\n",
        "                    commission_usd=float(commission),\n",
        "                    costs_charged_usd=float(costs),\n",
        "                ))\n",
        "        equity += gross_pnl - costs\n",
        "        peak_equity = max(peak_equity, equity)\n",
        "        equity_series.append(equity)\n",
        "        step_returns.append((gross_pnl - costs) / max(abs(equity_series[-2]), 1e-9))\n",
        "\n",
        "        # 4) Update trade state (entries, exits, reversals)\n",
        "        if (prev_pos == 0 and desired_pos != 0) or (np.sign(desired_pos) != np.sign(prev_pos) and desired_pos != 0):\n",
        "            entry_price = float(close[t])\n",
        "            entry_step = int(t)\n",
        "            best_price = entry_price\n",
        "            be_activated = False\n",
        "            stop_level = None\n",
        "        elif desired_pos == 0 and prev_pos != 0:\n",
        "            entry_price = 0.0\n",
        "            entry_step = None\n",
        "            best_price = 0.0\n",
        "            be_activated = False\n",
        "            stop_level = None\n",
        "        elif desired_pos == prev_pos and desired_pos != 0:\n",
        "            if desired_pos > 0:\n",
        "                best_price = max(best_price, float(close[t]))\n",
        "            else:\n",
        "                best_price = min(best_price, float(close[t]))\n",
        "        position = desired_pos\n",
        "\n",
        "    # Always return a 3-tuple for type stability; trade_reports may be None\n",
        "    return np.asarray(equity_series, dtype=np.float64), np.asarray(step_returns, dtype=np.float64), trade_reports\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Izp94ERhcrSt",
      "metadata": {
        "id": "Izp94ERhcrSt"
      },
      "source": [
        "# 7) Calmar Callback\n",
        "Early stopping by Calmar on validation backtests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "sYe3YHXOcrSu",
      "metadata": {
        "id": "sYe3YHXOcrSu"
      },
      "outputs": [],
      "source": [
        "# 7) Calmar Callback — validation selection\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.logger import Figure\n",
        "\n",
        "class CalmarCallback(BaseCallback):\n",
        "    def __init__(self, eval_env_ctor, eval_env_kwargs, eval_freq, best_model_save_path, guardian_kwargs=None, verbose=1, early_stop_patience=None, early_stop_min_delta=0.0, early_stop_target=None):\n",
        "        super().__init__(verbose)\n",
        "        self.eval_env_ctor = eval_env_ctor\n",
        "        self.eval_env_kwargs = eval_env_kwargs or {}\n",
        "        self.eval_freq = int(eval_freq)\n",
        "        self.best_model_save_path = best_model_save_path\n",
        "        self.guardian_kwargs = guardian_kwargs or {}\n",
        "        self.best_calmar = -np.inf\n",
        "        # Early stopping config\n",
        "        self.early_patience = (int(early_stop_patience) if early_stop_patience is not None else None)\n",
        "        self.early_min_delta = float(early_stop_min_delta)\n",
        "        self.early_target = (float(early_stop_target) if early_stop_target is not None else None)\n",
        "        self._no_improve_evals = 0\n",
        "        # live logging defaults\n",
        "        self.log_tb = True\n",
        "        self.plot_figures = True\n",
        "        self.save_csv = False\n",
        "        try:\n",
        "            import os as _os\n",
        "            self.log_dir = _os.path.dirname(best_model_save_path)\n",
        "        except Exception:\n",
        "            self.log_dir = None\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.eval_freq != 0:\n",
        "            return True\n",
        "        eval_env = self.eval_env_ctor(**self.eval_env_kwargs)\n",
        "        guardian = Guardian(**self.guardian_kwargs)\n",
        "        # Collect trade_reports to log number of trades during validation\n",
        "        equity, step_returns, trade_reports = run_backtest(self.model, eval_env, guardian, deterministic=True, collect_reports=True)\n",
        "        calmar = calmar_ratio(equity)\n",
        "        sharpe = sharpe_ratio(step_returns)\n",
        "        mdd_v = max_drawdown(equity)\n",
        "        cagr_v = cagr_from_equity(equity)\n",
        "        trades_count = len(trade_reports) if trade_reports is not None else 0\n",
        "        if self.verbose:\n",
        "            print(f'[CalmarCallback] step={self.n_calls} calmar={calmar:.4f} best={self.best_calmar:.4f} | sharpe={sharpe:.3f} mdd={mdd_v:.2%} cagr={cagr_v:.2%} | trades={trades_count}')\n",
        "        # TensorBoard scalars + figures\n",
        "        if self.log_tb:\n",
        "            self.logger.record('eval/calmar', float(calmar))\n",
        "            self.logger.record('eval/sharpe', float(sharpe))\n",
        "            self.logger.record('eval/mdd', float(mdd_v))\n",
        "            self.logger.record('eval/cagr', float(cagr_v))\n",
        "            self.logger.record('eval/trades', int(trades_count))\n",
        "            if self.plot_figures:\n",
        "                fig1 = plt.figure(figsize=(8, 2.4))\n",
        "                plt.plot(equity)\n",
        "                plt.title('Equity (val)')\n",
        "                plt.grid(True)\n",
        "                self.logger.record('eval/equity_curve', Figure(fig1, close=True), exclude=('stdout',))\n",
        "                dd = compute_drawdown(equity)\n",
        "                fig2 = plt.figure(figsize=(8, 2.0))\n",
        "                plt.plot(dd)\n",
        "                plt.title('Drawdown (val)')\n",
        "                plt.grid(True)\n",
        "                self.logger.record('eval/drawdown_curve', Figure(fig2, close=True), exclude=('stdout',))\n",
        "        # Optional CSV snapshot\n",
        "        if self.save_csv and self.log_dir is not None:\n",
        "            try:\n",
        "                import os, numpy as _np\n",
        "                os.makedirs(self.log_dir, exist_ok=True)\n",
        "                _np.savetxt(os.path.join(self.log_dir, f'equity_step_{self.n_calls}.csv'), equity, delimiter=',')\n",
        "            except Exception as e:\n",
        "                if self.verbose:\n",
        "                    print('[CalmarCallback] CSV save failed:', e)\n",
        "        improved = (calmar > (self.best_calmar + self.early_min_delta))\n",
        "        if improved:\n",
        "            self.best_calmar = calmar\n",
        "            self._no_improve_evals = 0\n",
        "            self.model.save(self.best_model_save_path)\n",
        "        else:\n",
        "            self._no_improve_evals += 1\n",
        "        # Early target stop\n",
        "        if (self.early_target is not None) and (calmar >= self.early_target):\n",
        "            if self.verbose:\n",
        "                print(f'[CalmarCallback] Early stop: target calmar {self.early_target:.4f} reached at step={self.n_calls}.')\n",
        "            return False\n",
        "        # Early patience stop\n",
        "        if (self.early_patience is not None) and (self._no_improve_evals >= self.early_patience):\n",
        "            if self.verbose:\n",
        "                print(f'[CalmarCallback] Early stop: no improvement in {self.early_patience} evals (best={self.best_calmar:.4f}).')\n",
        "            return False\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entropy_sched_hdr",
      "metadata": {
        "id": "entropy_sched_hdr"
      },
      "source": [
        "# 7b) Entropy Schedule Callback\n",
        "Anneal PPO entropy coefficient from a higher initial value to a lower final value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entropy_sched_code",
      "metadata": {
        "id": "entropy_sched_code"
      },
      "outputs": [],
      "source": [
        "# 7b) Entropy Schedule Callback — linear decay of ent_coef\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "class EntropyScheduleCallback(BaseCallback):\n",
        "    def __init__(self, start: float, end: float, total_timesteps: int, verbose: int = 0):\n",
        "        super().__init__(verbose)\n",
        "        self.start = float(start)\n",
        "        self.end = float(end)\n",
        "        self.total_timesteps = int(total_timesteps)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # num_timesteps = total env steps seen by the model\n",
        "        progress = min(1.0, self.num_timesteps / max(self.total_timesteps, 1))\n",
        "        current = self.start + (self.end - self.start) * progress\n",
        "        try:\n",
        "            # PPO reads self.ent_coef during train(); updating here anneals it over time\n",
        "            self.model.ent_coef = float(current)\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            self.logger.record('train/ent_coef', float(current))\n",
        "        except Exception:\n",
        "            pass\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lqrrzL21crSu",
      "metadata": {
        "id": "lqrrzL21crSu"
      },
      "source": [
        "# 8) Training — SB3 PPO\n",
        "Vectorized envs, CalmarCallback, and learn() loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0edd20df",
      "metadata": {
        "id": "0edd20df"
      },
      "outputs": [],
      "source": [
        "# 8) Training — SB3 PPO\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "\n",
        "def make_train_env():\n",
        "    return MNQEmbEnv(\n",
        "        npz_path=TRAIN_NPZ, meta_path=META_JSON, ohlc_csv_path=TRAIN_OHLC_CSV, ohlc_resample_rule=OHLC_RESAMPLE_RULE, episode_length=EPISODE_LENGTH,\n",
        "        point_value=POINT_VALUE_MNQ, fixed_commission_usd=FIXED_COMMISSION_USD,\n",
        "        fixed_slippage_usd=FIXED_SLIPPAGE_USD, apply_slippage_costs=TRAIN_SLIPPAGE_ON,\n",
        "        drawdown_penalty_coeff=DRAWDOWN_PENALTY_COEFF,\n",
        "        profit_keeping_bonus_coeff=PROFIT_KEEPING_BONUS_COEFF,\n",
        "        patience_bonus=PATIENCE_BONUS, choppy_atr_to_price_max=CHOPPY_ATR_TO_PRICE_MAX,\n",
        "        max_episode_drawdown_usd=MAX_EPISODE_DRAWDOWN_USD, seed=SEED\n",
        "    )\n",
        "\n",
        "def make_val_env():\n",
        "    return MNQEmbEnv(\n",
        "        npz_path=VAL_NPZ, meta_path=META_JSON, ohlc_csv_path=VAL_OHLC_CSV, ohlc_resample_rule=OHLC_RESAMPLE_RULE, episode_length=EPISODE_LENGTH,\n",
        "        point_value=POINT_VALUE_MNQ, fixed_commission_usd=FIXED_COMMISSION_USD,\n",
        "        fixed_slippage_usd=FIXED_SLIPPAGE_USD, apply_slippage_costs=False,\n",
        "        drawdown_penalty_coeff=DRAWDOWN_PENALTY_COEFF,\n",
        "        profit_keeping_bonus_coeff=PROFIT_KEEPING_BONUS_COEFF,\n",
        "        patience_bonus=PATIENCE_BONUS, choppy_atr_to_price_max=CHOPPY_ATR_TO_PRICE_MAX,\n",
        "        max_episode_drawdown_usd=MAX_EPISODE_DRAWDOWN_USD, seed=SEED+1\n",
        "    )\n",
        "\n",
        "vec_env = VecMonitor(DummyVecEnv([make_train_env for _ in range(N_ENVS)]), filename=None)\n",
        "# Use a stable, lighter policy to avoid degenerate early behavior\n",
        "from torch import nn\n",
        "policy_kwargs = dict(net_arch=[1024, 512], activation_fn=nn.SiLU)\n",
        "\n",
        "model = PPO('MlpPolicy', vec_env, policy_kwargs=policy_kwargs, tensorboard_log=LOG_DIR, seed=SEED, **PPO_KW)\n",
        "\n",
        "# Guardian preset switcher via toggle\n",
        "_sl_mult = 1.5 if GUARDIAN_TIGHT else GUARDIAN_SL_ATR_MULTIPLIER\n",
        "_ts_mult = 1.5 if GUARDIAN_TIGHT else GUARDIAN_TS_ATR_MULTIPLIER\n",
        "_be_act = 1.0 if GUARDIAN_TIGHT else GUARDIAN_BE_ACTIVATION_ATR_MULTIPLIER\n",
        "\n",
        "calmar_cb = CalmarCallback(\n",
        "    eval_env_ctor=MNQEmbEnv,\n",
        "    eval_env_kwargs=dict(\n",
        "        npz_path=VAL_NPZ, meta_path=META_JSON, ohlc_csv_path=VAL_OHLC_CSV, ohlc_resample_rule=OHLC_RESAMPLE_RULE, episode_length=EPISODE_LENGTH,\n",
        "        point_value=POINT_VALUE_MNQ, fixed_commission_usd=FIXED_COMMISSION_USD,\n",
        "        fixed_slippage_usd=FIXED_SLIPPAGE_USD, apply_slippage_costs=EVAL_SLIPPAGE_ON,\n",
        "        drawdown_penalty_coeff=DRAWDOWN_PENALTY_COEFF,\n",
        "        profit_keeping_bonus_coeff=PROFIT_KEEPING_BONUS_COEFF,\n",
        "        patience_bonus=PATIENCE_BONUS, choppy_atr_to_price_max=CHOPPY_ATR_TO_PRICE_MAX,\n",
        "        max_episode_drawdown_usd=MAX_EPISODE_DRAWDOWN_USD, seed=SEED+123\n",
        "    ),\n",
        "    eval_freq=EVAL_FREQ_STEPS,\n",
        "    best_model_save_path=BEST_MODEL_PATH,\n",
        "    guardian_kwargs=dict(point_value=POINT_VALUE_MNQ, sl_atr_mult=_sl_mult, ts_atr_mult=_ts_mult, be_activation_atr_mult=_be_act, be_plus_ticks=GUARDIAN_BE_PLUS_TICKS),\n",
        "    verbose=1,\n",
        "    early_stop_patience=5,          # stop if no Calmar improvement for 5 evals\n",
        "    early_stop_min_delta=0.0,       # require strictly better Calmar\n",
        "    early_stop_target=None          # or set a target Calmar to stop early\n",
        ")\n",
        "\n",
        "# Train with Calmar validation only (entropy schedule disabled for stability)\n",
        "model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=calmar_cb, progress_bar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-BF0Js9wcrSu",
      "metadata": {
        "id": "-BF0Js9wcrSu"
      },
      "source": [
        "# 9) Final Backtest & Plots\n",
        "Evaluate best model on the test split with Guardian and visualize results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "39f60fdf",
      "metadata": {
        "id": "39f60fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "6ee780d3-a7b6-4278-9157-c27d8082ef48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Calmar: 0.000 | Sharpe: 0.000 | MDD: 0.00% | CAGR: 0.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 9) Final Backtest & Plots — test split evaluation\n",
        "from stable_baselines3 import PPO\n",
        "best_model = PPO.load(BEST_MODEL_PATH, device='auto')\n",
        "test_env = MNQEmbEnv(\n",
        "    npz_path=TEST_NPZ, meta_path=META_JSON, ohlc_csv_path=TEST_OHLC_CSV, ohlc_resample_rule=OHLC_RESAMPLE_RULE, episode_length=10**9,\n",
        "    point_value=POINT_VALUE_MNQ, fixed_commission_usd=FIXED_COMMISSION_USD,\n",
        "    fixed_slippage_usd=FIXED_SLIPPAGE_USD, apply_slippage_costs=EVAL_SLIPPAGE_ON,\n",
        "    drawdown_penalty_coeff=DRAWDOWN_PENALTY_COEFF,\n",
        "    profit_keeping_bonus_coeff=PROFIT_KEEPING_BONUS_COEFF,\n",
        "    patience_bonus=PATIENCE_BONUS, choppy_atr_to_price_max=CHOPPY_ATR_TO_PRICE_MAX,\n",
        "    max_episode_drawdown_usd=1e12, seed=SEED+999\n",
        ")\n",
        "# Guardian preset switcher for test as well\n",
        "_sl_mult = 1.5 if GUARDIAN_TIGHT else GUARDIAN_SL_ATR_MULTIPLIER\n",
        "_ts_mult = 1.5 if GUARDIAN_TIGHT else GUARDIAN_TS_ATR_MULTIPLIER\n",
        "_be_act = 1.0 if GUARDIAN_TIGHT else GUARDIAN_BE_ACTIVATION_ATR_MULTIPLIER\n",
        "# Guardian using same preset/toggle as training\n",
        "guardian = Guardian(point_value=POINT_VALUE_MNQ,\n",
         "                     sl_atr_mult=_sl_mult,\n",
         "                     ts_atr_mult=_ts_mult,\n",
         "                     be_activation_atr_mult=_be_act,\n",
         "                     be_plus_ticks=GUARDIAN_BE_PLUS_TICKS)\n",
        "equity, step_returns, trade_reports = run_backtest(best_model, test_env, guardian, deterministic=True, collect_reports=True)\n",
        "# Log trade count and breakdown\n",
        "num_trades = len(trade_reports) if trade_reports is not None else 0\n",
        "num_longs = sum(1 for r in (trade_reports or []) if r.get('side', 0) > 0)\n",
        "num_shorts = sum(1 for r in (trade_reports or []) if r.get('side', 0) < 0)\n",
        "print(f'Trades: {num_trades} (long: {num_longs}, short: {num_shorts})')\n",
        "\n",
        "calmar = calmar_ratio(equity)\n",
        "sharpe = sharpe_ratio(step_returns)\n",
        "mdd = max_drawdown(equity)\n",
        "cagr = cagr_from_equity(equity)\n",
        "print(f'Test Calmar: {calmar:.3f} | Sharpe: {sharpe:.3f} | MDD: {mdd:.2%} | CAGR: {cagr:.2%}')\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(equity)\n",
        "plt.title('Equity Curve (Test)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "dd = compute_drawdown(equity)\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(dd)\n",
        "plt.title('Drawdown (Test)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tb_viewer_hdr",
      "metadata": {
        "id": "tb_viewer_hdr"
      },
      "source": [
        "# 10) TensorBoard Viewer\n",
        "Visualize training and evaluation logs recorded by SB3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tb_viewer_cell",
      "metadata": {
        "id": "tb_viewer_cell"
      },
      "outputs": [],
      "source": [
        "# 10) TensorBoard Viewer — launch inside notebook\n",
        "%load_ext tensorboard\n",
        "print(f\"Using LOG_DIR={LOG_DIR}\")\n",
        "%tensorboard --logdir \"$LOG_DIR\" --port 6006\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XWqhE-eMcrSn",
        "9QptH4HRcrSp",
        "y8FFJ5m-crSq",
        "a2191fec",
        "bsCOCr0ocrSs",
        "Izp94ERhcrSt"
      ],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
